[{"authors":["Chaohan Wang"],"categories":null,"content":"Chaohan is a PhD candidate at Australian Institute for Machine Learning. He is under the supervision of A Prof. Qi Wu and Dr. Yutong Xie. His research interest is Arttifical Intelligence in Medicine (AIM).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1164c3b18298e6d28b6813c678adf95e","permalink":"/author/chaohan-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chaohan-wang/","section":"authors","summary":"Chaohan is a PhD candidate at Australian Institute for Machine Learning. He is under the supervision of A Prof. Qi Wu and Dr. Yutong Xie. His research interest is Arttifical Intelligence in Medicine (AIM).","tags":null,"title":"Chaohan Wang","type":"authors"},{"authors":["ChaoruiDeng"],"categories":null,"content":"Chaorui was a phd student at The University of Adelaide under the supervision of Prof. Qi Wu. He received his master‚Äôs degree from South China University of Technology under the supervision of Prof. Mingkui Tan. He has also worked as an research intern in Microsoft Research Asia under the supervision of Dr. Jingdong Wang. His research interest is currently focused on the vision-and-language area, especially on multi-modal representation learning and open-vocabulary recognition.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"67b7210bf8ef526416a5f369a4436433","permalink":"/author/chaorui-deng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chaorui-deng/","section":"authors","summary":"Chaorui was a phd student at The University of Adelaide under the supervision of Prof. Qi Wu. He received his master‚Äôs degree from South China University of Technology under the supervision of Prof.","tags":null,"title":"Chaorui Deng","type":"authors"},{"authors":["ChongyangZhao"],"categories":null,"content":"Chongyang was an MPhil student at The University of Adelaide under the supervision of A/Prof. Qi Wu and Dr. Yuankai Qi. Before that he obtained his bachelor degree from Beijing Jiaotong University, supervised by Prof. Runmin Cong. His research interests include Computer Vision and Deep Learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c0431afd4033dab2c3c1f8ebadd1c594","permalink":"/author/chongyang-zhao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chongyang-zhao/","section":"authors","summary":"Chongyang was an MPhil student at The University of Adelaide under the supervision of A/Prof. Qi Wu and Dr. Yuankai Qi. Before that he obtained his bachelor degree from Beijing Jiaotong University, supervised by Prof.","tags":null,"title":"Chongyang Zhao","type":"authors"},{"authors":["CristianRodriguezOpazo"],"categories":null,"content":"Cristian Rodriguez Opazo is a research engineer and computer scientist with a broad interest in robotics, computer vision and machine learning. Working in research for more than eight years, creating state-of-the-art algorithms to solve challenging tasks in different areas of computer vision. Experienced to reproduce state-of-the-art solutions. Demonstrated capability to work independently and as part of a team.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a229959edebcfbdc9d7caa09c02c7ea6","permalink":"/author/cristian-rodriguez-opazo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/cristian-rodriguez-opazo/","section":"authors","summary":"Cristian Rodriguez Opazo is a research engineer and computer scientist with a broad interest in robotics, computer vision and machine learning. Working in research for more than eight years, creating state-of-the-art algorithms to solve challenging tasks in different areas of computer vision.","tags":null,"title":"Cristian¬†Rodriguez¬†Opazo","type":"authors"},{"authors":["FengChen"],"categories":null,"content":"Feng Chen is a PhD student of the School of Computer Science of the University of Adelaide. He is under the supervision of Dr. Qi Wu and Dr. Bohan Zhuang. He has a broad research interest in vision-language processing. Currently, Feng Chen is focusing on the problem of efficient text2image generation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f19f8e1b41438fdba331970ad90eb806","permalink":"/author/feng-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/feng-chen/","section":"authors","summary":"Feng Chen is a PhD student of the School of Computer Science of the University of Adelaide. He is under the supervision of Dr. Qi Wu and Dr. Bohan Zhuang. He has a broad research interest in vision-language processing.","tags":null,"title":"Feng Chen","type":"authors"},{"authors":["Gengze Zhou"],"categories":null,"content":"Gengze Zhou is a Ph.D. student from the Australian Institute for Machine Learning at the University of Adelaide, supervised by A/Prof. Qi Wu. Gengze has broad research interests in Computer Vision, Natural Language Processing, and Robotics. Currently, his main research is on Embodied AI and Large-scale Multimodality Models.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"29ae991bb0a440f781f37fab720083d5","permalink":"/author/gengze-zhou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gengze-zhou/","section":"authors","summary":"Gengze Zhou is a Ph.D. student from the Australian Institute for Machine Learning at the University of Adelaide, supervised by A/Prof. Qi Wu. Gengze has broad research interests in Computer Vision, Natural Language Processing, and Robotics.","tags":null,"title":"Gengze Zhou","type":"authors"},{"authors":["JianZhou"],"categories":null,"content":"Jian Zhou is a second-year MPhil candidate at the Australian Institute for Machine Learning (AIML), supervised by A/Prof. Qi Wu. He has a solid background in the theoretical foundations of deep learning and embodied AI, complemented by experience in control theory and robot kinematics, computer vision and 3D reconstruction, digital and analog circuits and electrical machinery, as well as mechanical structures and mechanics of materials. His current research interests include imitation learning, reinforcement learning, and the design of vision-language-action (VLA) models, with the long-term goal of developing theoretically grounded methods for generalist household robots.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"15fe73ff6e1d6fa36465238318e6a12f","permalink":"/author/jian-zhou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jian-zhou/","section":"authors","summary":"Jian Zhou is a second-year MPhil candidate at the Australian Institute for Machine Learning (AIML), supervised by A/Prof. Qi Wu. He has a solid background in the theoretical foundations of deep learning and embodied AI, complemented by experience in control theory and robot kinematics, computer vision and 3D reconstruction, digital and analog circuits and electrical machinery, as well as mechanical structures and mechanics of materials.","tags":null,"title":"Jian Zhou","type":"authors"},{"authors":["MahdiKazemiMoghaddam"],"categories":null,"content":"Mahdi is a Ph.D student at the Australian Institute for Machine Learning in Adelaide, supervised by Prof. Javen Shi, Dr. Qi Wu and Dr. Eshan Abbasnejad. Previously, he finished his Honours Degree of Bachelor of Computer Science at the University of Adelaide, with First class Honours, where he was awarded the faculty‚Äôs Valedictorian (among eight schools) and the Dean‚Äôs Academic Excellence Award for his outstanding achievements. His research interests include visual navigation and reinforcement learning in general.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d6d24c4a7d2af7d31c34c5f528174bfd","permalink":"/author/mahdi-kazemi-moghaddam/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mahdi-kazemi-moghaddam/","section":"authors","summary":"Mahdi is a Ph.D student at the Australian Institute for Machine Learning in Adelaide, supervised by Prof. Javen Shi, Dr. Qi Wu and Dr. Eshan Abbasnejad. Previously, he finished his Honours Degree of Bachelor of Computer Science at the University of Adelaide, with First class Honours, where he was awarded the faculty‚Äôs Valedictorian (among eight schools) and the Dean‚Äôs Academic Excellence Award for his outstanding achievements.","tags":null,"title":"Mahdi¬†Kazemi¬†Moghaddam","type":"authors"},{"authors":["Qi Chen"],"categories":null,"content":"Qi Chen is currently a postdoctoral researcher at the University of Adelaide. He received his Ph.D. in computer science from the University of Adelaide in 2024. Before that, he received a Master\u0026rsquo;s degree from the School of Software Engineering at South China University of Technology, China, in 2020, and a Bachelor\u0026rsquo;s degree from the same university in 2017. His research focuses on computer vision, multi-modality, and generative models. He serves as the reviewer for several top-tier conferences and journals including CVPR, ICML, ICLR, NeurIPS, ICCV, ECCV, TPAMI, etc.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"11a62f193340e675da3132f4610a165e","permalink":"/author/qi-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/qi-chen/","section":"authors","summary":"Qi Chen is currently a postdoctoral researcher at the University of Adelaide. He received his Ph.D. in computer science from the University of Adelaide in 2024. Before that, he received a Master\u0026rsquo;s degree from the School of Software Engineering at South China University of Technology, China, in 2020, and a Bachelor\u0026rsquo;s degree from the same university in 2017.","tags":null,"title":"Qi Chen","type":"authors"},{"authors":["Qi Wu"],"categories":null,"content":"My research interests are mainly in computer vision and machine learning. My previous research projects include modeling visual objects regardless of depictive styles and image understanding using contextual cues. I am currently leading a small team at the Adelaide to research on the topic of Vision-and-Language.\nI have been in the computer vision filed for nearly 6 years and I have a strong track record in this field. Currently, I am working on the vision to language problem and I am especially an expert in the image captioning and visual question answering (VQA). In 2015, my image captioning model and VQA model achieved the leading performance in the Microsoft COCO Image Captioning Challenges and VQA Challenges. I have published several papers in the top journals such as IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), IEEE Signal Processing Magazine (SPM), Computer Vision and Image Understanding (CVIU). I also have published several papers on the top conference, such as International Joint Conference on Artificial Intelligence (IJCAI), AAAI, The Conference on Computer Vision and Pattern Recognition (CVPR) and the European Conference on Computer Vision (ECCV), and so on.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"96138a908bad730e7775053554425355","permalink":"/author/qi-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/qi-wu/","section":"authors","summary":"My research interests are mainly in computer vision and machine learning. My previous research projects include modeling visual objects regardless of depictive styles and image understanding using contextual cues. I am currently leading a small team at the Adelaide to research on the topic of Vision-and-Language.","tags":null,"title":"Qi Wu","type":"authors"},{"authors":["QunchaoJin"],"categories":null,"content":"Qunchao Jin is a PhD student at the University of Adelaide.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ccab1e88fc89273e73c2dcadb207da2f","permalink":"/author/qunchao-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/qunchao-jin/","section":"authors","summary":"Qunchao Jin is a PhD student at the University of Adelaide.","tags":null,"title":"Qunchao Jin","type":"authors"},{"authors":["ShuaiFu"],"categories":null,"content":"Shuai Fu is a PhD student at the University of Adelaide.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"af038e28cab11c575b2e8d245c493111","permalink":"/author/shuai-fu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shuai-fu/","section":"authors","summary":"Shuai Fu is a PhD student at the University of Adelaide.","tags":null,"title":"Shuai Fu","type":"authors"},{"authors":["Sihao Lin"],"categories":null,"content":"See My Personal Website: https://sihaoevery.github.io/\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"45300c6d3a7f6d84ad44131a5d85cae0","permalink":"/author/sihao-lin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sihao-lin/","section":"authors","summary":"See My Personal Website: https://sihaoevery.github.io/","tags":null,"title":"Sihao Lin","type":"authors"},{"authors":["SinuoWang"],"categories":null,"content":"Sinuo is a PhD candidate at the Australian Institute for Machine Learning (AIML). Under the supervision of A/Prof. Qi Wu and Dr. Yutong Xie, her PhD research focuses on vision-language pre-training for the medical domain. Prior to her doctoral studies, Sinuo obtained her Bachelor\u0026rsquo;s degree in Electrical and Electronic Engineering (Autonomous Systems) with Honours at the University of Adelaide. She continued her academic journey at the same institution and obtained a Master\u0026rsquo;s degree in Artificial Intelligence and Machine Learning in 2023. Her accomplishments include receiving the Executive Dean‚Äôs Recognition of Academic Excellence in 2022 and winning 1st place with her RoboBreizh team at the international robotics competition RoboCup@Home SSPL League held in Bordeaux, France in 2023.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9d53eef80e5f7982d2013974d578ae12","permalink":"/author/sinuo-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sinuo-wang/","section":"authors","summary":"Sinuo is a PhD candidate at the Australian Institute for Machine Learning (AIML). Under the supervision of A/Prof. Qi Wu and Dr. Yutong Xie, her PhD research focuses on vision-language pre-training for the medical domain.","tags":null,"title":"Sinuo Wang","type":"authors"},{"authors":["XiangyuShi"],"categories":null,"content":"Xiangyu Shi is a PhD student at the University of Adelaide.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"791bfa975722926906339db812703834","permalink":"/author/xiangyu-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xiangyu-shi/","section":"authors","summary":"Xiangyu Shi is a PhD student at the University of Adelaide.","tags":null,"title":"Xiangyu Shi","type":"authors"},{"authors":["Xinyu Wang"],"categories":null,"content":"Xinyu is currently a Postdoctoral Research Fellow at the Centre for Augmented Reasoning, Australian Institute for Machine Learning, working with Prof. Qi Wu. He received his Ph.D. degree from the School of Computer and Mathematical Sciences at The University of Adelaide, Australia, under the supervision of Prof. Chunhua Shen.\nXinyu\u0026rsquo;s research interests lie at the intersection of Computer Vision and Natural Language Processing, especially in topics related to Multi-modal Large Language Models, Optical Character Recognition, and other Multi-modality Applications. Recently, he has been exploring the use of instruction-tuning techniques to adapt text-based LLMs to broader modalities, thereby enabling the processing of more complex tasks. Xinyu has co-authored publications in notable conferences and journals such as CVPR, ACMMM, TPAMI, IJCV, TMM, TCSVT, and PR.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0e2d5d0864d4e3709e6eacd963ac2d1b","permalink":"/author/xinyu-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xinyu-wang/","section":"authors","summary":"Xinyu is currently a Postdoctoral Research Fellow at the Centre for Augmented Reasoning, Australian Institute for Machine Learning, working with Prof. Qi Wu. He received his Ph.D. degree from the School of Computer and Mathematical Sciences at The University of Adelaide, Australia, under the supervision of Prof.","tags":null,"title":"Xinyu Wang","type":"authors"},{"authors":["XunyiZhao"],"categories":null,"content":"Xunyi Zhao is a PhD student at the Australian Institute for Machine Learning, University of Adelaide, supervised by A/Prof. Qi Wu and A/Prof. Jiajun Liu. He completed his Bachelor‚Äôs degree in Software Engineering at the University of Tasmania and earned his Master‚Äôs in Artificial Intelligence at the University of Adelaide. His current research focuses on Embodied AI, particularly in areas such as Vision-Language Navigation and robotic perception and decision-making.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"5fd200817d6469820550572054a6f1cd","permalink":"/author/xunyi-zhao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xunyi-zhao/","section":"authors","summary":"Xunyi Zhao is a PhD student at the Australian Institute for Machine Learning, University of Adelaide, supervised by A/Prof. Qi Wu and A/Prof. Jiajun Liu. He completed his Bachelor‚Äôs degree in Software Engineering at the University of Tasmania and earned his Master‚Äôs in Artificial Intelligence at the University of Adelaide.","tags":null,"title":"Xunyi Zhao","type":"authors"},{"authors":["YanyuanQiao"],"categories":null,"content":"Yanyuan Qiao is a Postdoctoral Research Fellow working with A.P. Qi Wu, at Australian Institute for Machine Learning (AIML), The University of Adelaide, where she completed her Ph.D. in Computer Science, under the supervision of A.P. Qi Wu and Dr. Yuankai Qi. Her research interests lie broadly in the field of Vision-and-Language and Embodied AI, especially in Vision-and-Language Navigation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"52d558c47cf8f0bb493d82093d89c527","permalink":"/author/yanyuan-qiao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yanyuan-qiao/","section":"authors","summary":"Yanyuan Qiao is a Postdoctoral Research Fellow working with A.P. Qi Wu, at Australian Institute for Machine Learning (AIML), The University of Adelaide, where she completed her Ph.D. in Computer Science, under the supervision of A.","tags":null,"title":"Yanyuan Qiao","type":"authors"},{"authors":["YicongHong"],"categories":null,"content":"Yicong is a second-year PhD student of the College of Engineering and Computer Science of the Australian National University (ANU), he is under the supervision of Prof. Stephen Gould and Dr. Qi Wu. Yicong has a broad research interests in computer vision, natural language processing and robotics. Currently, he is focusing on the problem of Vision-and-Language Navigation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7de4e038ab49d499a5a3029d5b33f5af","permalink":"/author/yicong-hong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yicong-hong/","section":"authors","summary":"Yicong is a second-year PhD student of the College of Engineering and Computer Science of the Australian National University (ANU), he is under the supervision of Prof. Stephen Gould and Dr.","tags":null,"title":"Yicong Hong","type":"authors"},{"authors":["YuankaiQi"],"categories":null,"content":"During my Ph.D period, I mainly fouced on the visual object tracking task. I have published many papers regarding visual tracking on top venues, such as TPAMI, TIP, CVPR, ECCV, AAAI, etc. I have also achieved serval awards on visual tracking related international challenges, such as the Winner of DAVIS 2017, the runner-up of VisDrone 2018.\nNow, I focus more on vision-and-language navigation tasks and have published several papers on CVPR, ECCV, NeurIPS. In 2019, we proposed the remote object grounding task in real-indoor envirionments, hoping push forward the research of intelligent robots. Currently, I serve as reviewers for TPAMI, TIP, CVIU, TCSVT, PR, CVPR, AAAI, ICCV, etc.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bc3460e7dda3f59c4ff4ab2b1ece54ed","permalink":"/author/yuankai-qi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuankai-qi/","section":"authors","summary":"During my Ph.D period, I mainly fouced on the visual object tracking task. I have published many papers regarding visual tracking on top venues, such as TPAMI, TIP, CVPR, ECCV, AAAI, etc.","tags":null,"title":"Yuankai Qi","type":"authors"},{"authors":["YumingChen"],"categories":null,"content":"Yuming is a Master of Philosophy student at the Australian Institute for Machine Learning (AIML), University of Adelaide. He is jointly supervised by A/Prof. Qi Wu at the University of Adelaide and Dr. Yutong Xie at the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI). His research focuses on medical artificial intelligence, aiming to advance diagnostic and prognostic analysis in healthcare through cutting-edge AI technologies.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"58a53fd99cff0628dad3e0b706b4f7b9","permalink":"/author/yuming-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuming-chen/","section":"authors","summary":"Yuming is a Master of Philosophy student at the Australian Institute for Machine Learning (AIML), University of Adelaide. He is jointly supervised by A/Prof. Qi Wu at the University of Adelaide and Dr.","tags":null,"title":"Yuming Chen","type":"authors"},{"authors":["Yutong Xie"],"categories":null,"content":"Yutong is currently a Postdoctoral Research Fellow at Australian Institute for Machine Learning (AIML), part of The University of Adelaide (UoA), working with Dr. Qi Wu. She received her Ph.D. in the School of Computer Science and Engineering at Northwestern Polytechnical University (NPU), China, under the supervision of Prof. Yong Xia. She has also spent two years at UoA during her Ph.D. studies, under the supervision of Prof. Chunhua Shen and Dr. Johan Verjans.\nYutong\u0026rsquo;s focus is mainly on artificial intelligence in medical data analysis applications, aiming to develop smart solutions to assist medical professionals in the lesion and anatomical structure segmentation, and disease diagnosis and therapy. Recently, she has been investigating self-supervised/multi-modal learning to improve medical data analysis with limited annotations. Yutong has published over 10 peer-reviewed articles in top-tier journals/conferences such as IEEE-TMI, Medical Image Analysis, CVPR, IJCAI, MICCAI, and so on.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f2f586201df651075fe2b80ba41e7b0d","permalink":"/author/yutong-xie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yutong-xie/","section":"authors","summary":"Yutong is currently a Postdoctoral Research Fellow at Australian Institute for Machine Learning (AIML), part of The University of Adelaide (UoA), working with Dr. Qi Wu. She received her Ph.D. in the School of Computer Science and Engineering at Northwestern Polytechnical University (NPU), China, under the supervision of Prof.","tags":null,"title":"Yutong Xie","type":"authors"},{"authors":["ZeruiLi"],"categories":null,"content":"Zerui is a PhD student at the Australian Institute of Machine Learning (AIML), under the supervision of A/prof. Qi Wu and Dr. Yanyuan Qiao. His research focuses on Vision-and-Language Navigation in the Embodied AI domain. He is currently on the pathway to his doctoral studies. He completed his Bachelor‚Äôs degree in Electrical and Electronics Engineering (Computer Engineering) with Honours at the University of Adelaide in 2023. His accomplishments include winning 3rd place with the V3A team at the Robot Embodied Intelligence Challenge held by CCF China Software Conference in 2023.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7267a2e5c2cc60b74dfdf47091c44b42","permalink":"/author/zerui-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zerui-li/","section":"authors","summary":"Zerui is a PhD student at the Australian Institute of Machine Learning (AIML), under the supervision of A/prof. Qi Wu and Dr. Yanyuan Qiao. His research focuses on Vision-and-Language Navigation in the Embodied AI domain.","tags":null,"title":"Zerui Li","type":"authors"},{"authors":["ZhengYu"],"categories":null,"content":"Zheng Yu is a PhD student of School of Computer Science at the University of Adelaide, under the supervision of Dr. Qi Wu. Zheng Yu has a broad research interest in Vision and Language. Currently, he is focusing on the problem of multimodal efficient transfer learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a766c333f4715354a7d573d8c8ed11c0","permalink":"/author/zheng-yu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zheng-yu/","section":"authors","summary":"Zheng Yu is a PhD student of School of Computer Science at the University of Adelaide, under the supervision of Dr. Qi Wu. Zheng Yu has a broad research interest in Vision and Language.","tags":null,"title":"Zheng Yu","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\n  (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./line-chart.json\", function(chart) { Plotly.plot('chart-641853297', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  You might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^) = \\begin{cases} p_0^ \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}}  renders as\n Click to view the spoiler  You found me!    Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it üôå ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["admin"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"/people/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"People","tags":null,"title":"People","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"47a3f377d2455d0bd65d4ba1dc3e2ab2","permalink":"/project/r2r/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/r2r/","section":"project","summary":"Room to Room Navigation","tags":["VLN"],"title":"R2R","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"6c583ddc975f96cc394c3d9705a75eba","permalink":"/project/reverie/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/reverie/","section":"project","summary":"Remote Object Grounding","tags":["VLN"],"title":"REVERIE","type":"project"},{"authors":["admin","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n üëâ Get Started üìö View the documentation üí¨ Ask a question on the forum üë• Chat with the community üê¶ Twitter: @source_themes @GeorgeCushen #MadeWithAcademic üí° Request a feature or report a bug ‚¨ÜÔ∏è Updating? View the Update Guide and Release Notes ‚ù§Ô∏è Support development of Academic:  ‚òïÔ∏è Donate a coffee üíµ Become a backer on Patreon üñºÔ∏è Decorate your laptop or journal with an Academic sticker üëï Wear the T-shirt üë©‚Äçüíª Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Academic: the website builder for Hugo","type":"post"}]